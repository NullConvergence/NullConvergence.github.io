---
layout: default
name: Adversarial Benchmark
public: 0
description: #
---

## Adversarial Benchmark

I maintain a list of benchmarks for robustness of neural networks against adversarial example.

The list is meant as a guide for researchers and practitioners when navigating through adversarial defenses.

It can be accessed from the [Github repo](https://github.com/NullConvergence/adversarial-robustness-benchmarks/blob/master/index.md) or from [Github pages](https://nullconvergence.github.io/adversarial-robustness-benchmarks/)